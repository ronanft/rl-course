{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851dd6b8",
   "metadata": {},
   "source": [
    "https://gymnasium.farama.org/environments/box2d/lunar_lander/\n",
    "Implementar Q Learning para esse env.\n",
    "\n",
    "---\n",
    "## Action Space\n",
    "There are four discrete actions available:\n",
    "\n",
    "0: do nothing\n",
    "1: fire left orientation engine\n",
    "2: fire main engine\n",
    "3: fire right orientation engine\n",
    "\n",
    "## Observation Space\n",
    "The state is an 8-dimensional vector: the coordinates of the lander in x & y, its linear velocities in x & y, its angle, its angular velocity, and two booleans that represent whether each leg is in contact with the ground or not.\n",
    "\n",
    "## Rewards\n",
    "After every step a reward is granted. The total reward of an episode is the sum of the rewards for all the steps within that episode.\n",
    "For each step, the reward:\n",
    "\n",
    "is increased/decreased the closer/further the lander is to the landing pad.\n",
    "is increased/decreased the slower/faster the lander is moving.\n",
    "is decreased the more the lander is tilted (angle not horizontal).\n",
    "is increased by 10 points for each leg that is in contact with the ground.\n",
    "is decreased by 0.03 points each frame a side engine is firing.\n",
    "is decreased by 0.3 points each frame the main engine is firing.\n",
    "\n",
    "The episode receive an additional reward of -100 or +100 points for crashing or landing safely respectively.\n",
    "An episode is considered a solution if it scores at least 200 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147ec15",
   "metadata": {},
   "source": [
    "## Agente de Q Learning:\n",
    "https://gymnasium.farama.org/introduction/train_agent/\n",
    "\n",
    "## Tutoriais importantes!\n",
    "https://gymnasium.farama.org/tutorials/training_agents/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f317bc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"LunarLander-v3\") #, continuous=False, gravity=-10.0, enable_wind=False, wind_power=15.0, turbulence_power=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e6e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins per dimension for discretization\n",
    "bins_per_dim = [6, 6, 6, 6, 6, 6, 2, 2] # num_states = 186 thousands\n",
    "num_states = np.prod(bins_per_dim)\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "Q = np.zeros((num_states, num_actions))  # Q(s, a) = Q[state, action]\n",
    "\n",
    "discount = 1.0\n",
    "alpha = 0.1\n",
    "eps = .9\n",
    "max_episodes = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb983a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_observation(obs, bins_per_dim=None):\n",
    "    \"\"\"\n",
    "    Discretizes the LunarLander observation into a single integer index.\n",
    "    Args:\n",
    "        obs: array-like, shape (8,)\n",
    "        bins_per_dim: list or array of length 8, number of bins for each dimension\n",
    "    Returns:\n",
    "        int: unique discrete state index\n",
    "    \"\"\"\n",
    "    # Define reasonable bounds for each dimension (from env source/documentation)\n",
    "    low = np.array([-1.5, -0.5, -2.0, -2.0, -np.pi, -5.0, 0, 0])\n",
    "    high = np.array([1.5, 1.5, 2.0, 2.0, np.pi, 5.0, 1, 1])\n",
    "    obs = np.clip(obs, low, high)\n",
    "\n",
    "    if bins_per_dim is None:\n",
    "        bins_per_dim = [6, 6, 6, 6, 6, 6, 2, 2]  # 6 bins for continuous, 2 for booleans\n",
    "\n",
    "    # Discretize each dimension\n",
    "    discretized = []\n",
    "    for i in range(8):\n",
    "        if bins_per_dim[i] == 2:  # For leg contact (already 0 or 1)\n",
    "            discretized.append(int(obs[i]))\n",
    "        else:\n",
    "            bins = np.linspace(low[i], high[i], bins_per_dim[i] + 1)\n",
    "            discretized.append(np.digitize(obs[i], bins) - 1)\n",
    "            discretized[-1] = min(discretized[-1], bins_per_dim[i] - 1)  # Ensure in range\n",
    "\n",
    "    # Convert multi-dimensional bin to single integer (flattened index)\n",
    "    state_idx = 0\n",
    "    for i in range(8):\n",
    "        state_idx *= bins_per_dim[i]\n",
    "        state_idx += discretized[i]\n",
    "    return state_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda17bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(s):\n",
    "    if np.random.rand() < eps:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        return np.argmax(Q[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "855d3055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_update(s, a, r, s1, terminated):\n",
    "    if terminated:\n",
    "        max_q1 = 0\n",
    "    else:\n",
    "        max_q1 = np.max(Q[s1])\n",
    "\n",
    "    target = r + discount * max_q1\n",
    "    Q[s, a] += alpha * (target - Q[s, a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deac076d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m a \u001b[38;5;241m=\u001b[39m get_action(s)\n\u001b[0;32m     13\u001b[0m s1, r, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(a)\n\u001b[1;32m---> 14\u001b[0m s1_d \u001b[38;5;241m=\u001b[39m \u001b[43mdiscretize_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms1\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Corrigir aqui\u001b[39;00m\n\u001b[0;32m     15\u001b[0m q_update(s, a, r, s1_d, terminated)\n\u001b[0;32m     16\u001b[0m s \u001b[38;5;241m=\u001b[39m s1_d\n",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m, in \u001b[0;36mdiscretize_observation\u001b[1;34m(obs, bins_per_dim)\u001b[0m\n\u001b[0;32m     22\u001b[0m     discretized\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(obs[i]))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     bins \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhigh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins_per_dim\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     discretized\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mdigitize(obs[i], bins) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m     discretized[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(discretized[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], bins_per_dim[i] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Ensure in range\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mlinspace\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ronan\\anaconda3\\envs\\rl\\lib\\site-packages\\numpy\\core\\function_base.py:135\u001b[0m, in \u001b[0;36mlinspace\u001b[1;34m(start, stop, num, endpoint, retstep, dtype, axis)\u001b[0m\n\u001b[0;32m    132\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dt\n\u001b[0;32m    134\u001b[0m delta \u001b[38;5;241m=\u001b[39m stop \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m--> 135\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m ndim(delta))\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# In-place multiplication y *= delta/div is faster, but prevents the multiplicant\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# from overriding what class is produced, and thus prevents, e.g. use of Quantities,\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# see gh-7142. Hence, we multiply in place only for standard scalar types.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m _mult_inplace \u001b[38;5;241m=\u001b[39m _nx\u001b[38;5;241m.\u001b[39misscalar(delta)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time  # Add timing\n",
    "start_time = time.time()\n",
    "for episode in range(max_episodes):\n",
    "    observation, _ = env.reset()\n",
    "    s = discretize_observation(observation) # Continuous to discrete\n",
    "\n",
    "    # Make epsilon decay according to episode counter\n",
    "    if eps > 0.01:\n",
    "        eps *= 0.99\n",
    "    \n",
    "    while True:\n",
    "        a = get_action(s)\n",
    "        s1, r, terminated, truncated, _ = env.step(a)\n",
    "        s1_d = discretize_observation(s1)  # Corrigir aqui\n",
    "        q_update(s, a, r, s1_d, terminated)\n",
    "        s = s1_d\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "env.close()\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "de0484f0",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "Muitos minutos e não terminou de rodar... Tentamos 1 Mi de episódios e baixamos para 100k e nada!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8be37",
   "metadata": {},
   "source": [
    "---\n",
    "## Q-Learning no ambiente Taxi-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a410189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "env_taxi = gym.make('Taxi-v3')\n",
    "num_states_taxi = env_taxi.observation_space.n\n",
    "num_actions_taxi = env_taxi.action_space.n\n",
    "\n",
    "Q_taxi = np.zeros((num_states_taxi, num_actions_taxi))\n",
    "\n",
    "discount_taxi = 0.99\n",
    "alpha_taxi = 0.1\n",
    "eps_taxi = 0.9\n",
    "max_episodes_taxi = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "053995fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_taxi(s):\n",
    "    if np.random.rand() < eps_taxi:\n",
    "        return env_taxi.action_space.sample()\n",
    "    else:\n",
    "        return np.argmax(Q_taxi[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04788359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_update_taxi(s, a, r, s1, terminated):\n",
    "    if terminated:\n",
    "        max_q1 = 0\n",
    "    else:\n",
    "        max_q1 = np.max(Q_taxi[s1])\n",
    "    target = r + discount_taxi * max_q1\n",
    "    Q_taxi[s, a] += alpha_taxi * (target - Q_taxi[s, a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff4db91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxi-v3 training time: 2.34 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "for episode in range(max_episodes_taxi):\n",
    "    s, _ = env_taxi.reset()\n",
    "    if eps_taxi > 0.01:\n",
    "        eps_taxi *= 0.995\n",
    "    while True:\n",
    "        a = get_action_taxi(s)\n",
    "        s1, r, terminated, truncated, _ = env_taxi.step(a)\n",
    "        q_update_taxi(s, a, r, s1, terminated)\n",
    "        s = s1\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "env_taxi.close()\n",
    "end_time = time.time()\n",
    "print(f\"Taxi-v3 training time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acca8476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episódio 1: recompensa total = 8\n",
      "Episódio 2: recompensa total = 9\n",
      "Episódio 3: recompensa total = 8\n",
      "Episódio 4: recompensa total = 5\n",
      "Episódio 5: recompensa total = 12\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Executa o modelo treinado no Taxi-v3 por 5 episódios com renderização\n",
    "env_taxi = gym.make('Taxi-v3', render_mode='human')\n",
    "for ep in range(5):\n",
    "    s, _ = env_taxi.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        a = np.argmax(Q_taxi[s])\n",
    "        s, r, terminated, truncated, _ = env_taxi.step(a)\n",
    "        total_reward += r\n",
    "        done = terminated or truncated\n",
    "        time.sleep(0.5)  # Para visualizar melhor cada passo\n",
    "    print(f\"Episódio {ep+1}: recompensa total = {total_reward}\")\n",
    "env_taxi.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
